"""Improved MLA compression techniques.

Key improvements over basic SVD:
1. Calibration-aware SVD - finds optimal subspace from actual K/V outputs
2. Decoupled RoPE - separates positional encoding from compressed content
3. Joint K-V compression - single latent for both K and V (more efficient)
"""

import torch
import torch.nn as nn
from typing import Tuple, Optional, Dict, List
from tqdm import tqdm

from .utils import orthonormalize_columns


def calibration_aware_svd(
    W_k: torch.Tensor,
    W_v: torch.Tensor,
    hidden_states: torch.Tensor,
    d_latent: int,
    max_samples: int = 10000,
) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, Dict[str, float]]:
    """Calibration-aware SVD for better compression.

    Instead of SVD on W_k/W_v directly, we do SVD on the actual K/V outputs:
    - K = H @ W_k.T  (what the model actually computes)
    - SVD(K) finds the principal directions in K-space that matter for this data

    This typically captures 10-20% more energy than weight-only SVD because
    the hidden state distribution concentrates K/V in a lower-dimensional subspace.

    Args:
        W_k: Key projection weights (d_kv, d_model)
        W_v: Value projection weights (d_kv, d_model)
        hidden_states: Calibration hidden states (n_tokens, d_model)
        d_latent: Target latent dimension
        max_samples: Maximum calibration samples to use

    Returns:
        Tuple of (W_down_k, W_down_v, W_uk, W_uv, stats)
    """
    device = W_k.device
    dtype = W_k.dtype

    # Subsample if needed
    if hidden_states.size(0) > max_samples:
        indices = torch.randperm(hidden_states.size(0))[:max_samples]
        hidden_states = hidden_states[indices]

    # Move to same device and use float32 for SVD
    H = hidden_states.to(device).float()
    W_k_f32 = W_k.float()
    W_v_f32 = W_v.float()

    # Compute actual K and V outputs
    K = H @ W_k_f32.T  # (n_tokens, d_kv)
    V = H @ W_v_f32.T  # (n_tokens, d_kv)

    # SVD on K (transposed so we get right singular vectors as columns)
    # K.T has shape (d_kv, n_tokens)
    # We want the principal directions in d_kv space
    U_k, S_k, _ = torch.linalg.svd(K.T, full_matrices=False)
    U_v, S_v, _ = torch.linalg.svd(V.T, full_matrices=False)

    # Take top d_latent components
    W_uk = U_k[:, :d_latent]  # (d_kv, d_latent)
    W_uv = U_v[:, :d_latent]  # (d_kv, d_latent)

    # Compute energy captured
    energy_k = (S_k[:d_latent]**2).sum() / (S_k**2).sum()
    energy_v = (S_v[:d_latent]**2).sum() / (S_v**2).sum()

    # Compute optimal W_down: minimize ||K - (H @ W_down.T) @ W_u.T||
    # Solution: W_down = W_u.T @ W_k (same as before, but W_u is calibration-optimized)
    W_down_k = W_uk.T @ W_k_f32  # (d_latent, d_model)
    W_down_v = W_uv.T @ W_v_f32  # (d_latent, d_model)

    # Compute reconstruction error
    K_recon = (H @ W_down_k.T) @ W_uk.T
    V_recon = (H @ W_down_v.T) @ W_uv.T
    recon_err_k = torch.norm(K - K_recon) / torch.norm(K)
    recon_err_v = torch.norm(V - V_recon) / torch.norm(V)

    stats = {
        "k_energy": energy_k.item(),
        "v_energy": energy_v.item(),
        "k_recon_error": recon_err_k.item(),
        "v_recon_error": recon_err_v.item(),
    }

    return (
        W_down_k.to(dtype),
        W_down_v.to(dtype),
        W_uk.to(dtype),
        W_uv.to(dtype),
        stats
    )


def joint_kv_svd(
    W_k: torch.Tensor,
    W_v: torch.Tensor,
    hidden_states: torch.Tensor,
    d_latent: int,
    max_samples: int = 10000,
) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, Dict[str, float]]:
    """Joint K-V compression with shared latent (like DeepSeek MLA).

    Uses a SINGLE latent c that reconstructs both K and V:
    - c = H @ W_down.T
    - K = c @ W_uk.T
    - V = c @ W_uv.T

    This is more efficient (single latent instead of [c_k, c_v]) and
    allows the latent to capture shared structure between K and V.

    Args:
        W_k: Key projection weights (d_kv, d_model)
        W_v: Value projection weights (d_kv, d_model)
        hidden_states: Calibration hidden states (n_tokens, d_model)
        d_latent: Target latent dimension
        max_samples: Maximum calibration samples

    Returns:
        Tuple of (W_down, W_uk, W_uv, stats)
        - W_down: (d_latent, d_model) shared compression
        - W_uk: (d_kv, d_latent) K decompression
        - W_uv: (d_kv, d_latent) V decompression
    """
    device = W_k.device
    dtype = W_k.dtype

    if hidden_states.size(0) > max_samples:
        indices = torch.randperm(hidden_states.size(0))[:max_samples]
        hidden_states = hidden_states[indices]

    H = hidden_states.to(device).float()
    W_k_f32 = W_k.float()
    W_v_f32 = W_v.float()

    # Compute K and V
    K = H @ W_k_f32.T  # (n_tokens, d_kv)
    V = H @ W_v_f32.T  # (n_tokens, d_kv)

    # Stack K and V for joint SVD
    # This finds directions that are important for BOTH K and V
    KV = torch.cat([K, V], dim=1)  # (n_tokens, 2*d_kv)

    # SVD on hidden states weighted by importance to K and V
    # Alternative: SVD on H directly, weighted by how much each direction affects KV
    # H.T @ H gives covariance of hidden states
    # We want directions in H that most affect KV

    # Compute H.T @ KV to find which H directions matter for KV
    H_to_KV = H.T @ KV  # (d_model, 2*d_kv)

    # SVD to find optimal compression directions in H space
    U_h, S_h, Vh = torch.linalg.svd(H_to_KV, full_matrices=False)

    # W_down projects H to latent space using top directions
    W_down = U_h[:, :d_latent].T  # (d_latent, d_model)

    # Compute latent representations
    C = H @ W_down.T  # (n_tokens, d_latent)

    # Find optimal W_uk and W_uv to reconstruct K and V from C
    # Least squares: K â‰ˆ C @ W_uk.T => W_uk.T = (C.T @ C)^{-1} @ C.T @ K
    CtC_inv = torch.linalg.inv(C.T @ C + 1e-6 * torch.eye(d_latent, device=device))
    W_uk = (CtC_inv @ C.T @ K).T  # (d_kv, d_latent)
    W_uv = (CtC_inv @ C.T @ V).T  # (d_kv, d_latent)

    # Orthonormalize W_uk and W_uv for Stiefel manifold
    W_uk = orthonormalize_columns(W_uk)
    W_uv = orthonormalize_columns(W_uv)

    # Recompute W_down to be optimal for orthonormalized W_u
    # W_down = W_u.T @ W (for each)
    # But we have shared W_down, so we minimize joint error
    # This is approximate - could iterate to refine

    # Reconstruction
    K_recon = C @ W_uk.T
    V_recon = C @ W_uv.T

    recon_err_k = torch.norm(K - K_recon) / torch.norm(K)
    recon_err_v = torch.norm(V - V_recon) / torch.norm(V)

    stats = {
        "k_recon_error": recon_err_k.item(),
        "v_recon_error": recon_err_v.item(),
        "latent_dim": d_latent,
        "compression_ratio": (2 * W_k.shape[0]) / d_latent,  # 2*d_kv / d_latent
    }

    return W_down.to(dtype), W_uk.to(dtype), W_uv.to(dtype), stats


class DecoupledRoPECompression(nn.Module):
    """MLA Compression with decoupled RoPE (DeepSeek-style).

    Key insight: RoPE encodes position, which is hard to compress.
    Solution: Split K into:
    - K_rope: Small component that carries RoPE (not compressed)
    - K_content: Larger component for content (compressed)

    Final K = [K_rope, K_content_decompressed]

    This preserves positional information while still compressing content.
    """

    def __init__(
        self,
        d_model: int,
        d_kv: int,
        d_latent: int,
        d_rope: int = 64,  # Dimension for RoPE (not compressed)
    ):
        super().__init__()
        self.d_model = d_model
        self.d_kv = d_kv
        self.d_latent = d_latent
        self.d_rope = d_rope
        self.d_content = d_kv - d_rope  # Content dimension

        # RoPE projection (not compressed) - small
        self.W_rope_k = nn.Linear(d_model, d_rope, bias=False)
        self.W_rope_v = nn.Linear(d_model, d_rope, bias=False)  # V also gets some uncompressed

        # Content compression
        self.W_down_k = nn.Linear(d_model, d_latent, bias=False)
        self.W_down_v = nn.Linear(d_model, d_latent, bias=False)

        # Content decompression (Stiefel manifold)
        import geoopt
        from geoopt.manifolds import Stiefel

        self.stiefel = Stiefel(canonical=False)
        W_uk_init = torch.randn(self.d_content, d_latent)
        W_uv_init = torch.randn(self.d_content, d_latent)
        W_uk_init = orthonormalize_columns(W_uk_init)
        W_uv_init = orthonormalize_columns(W_uv_init)

        self.W_uk = geoopt.ManifoldParameter(W_uk_init, manifold=self.stiefel)
        self.W_uv = geoopt.ManifoldParameter(W_uv_init, manifold=self.stiefel)

    def compress(self, h: torch.Tensor) -> torch.Tensor:
        """Compress hidden states.

        Returns: (batch, seq, d_rope*2 + d_latent*2)
        - First d_rope: K_rope (uncompressed positional)
        - Next d_rope: V_rope (uncompressed)
        - Next d_latent: c_k (compressed K content)
        - Last d_latent: c_v (compressed V content)
        """
        h_f32 = h.float()

        k_rope = self.W_rope_k(h_f32)
        v_rope = self.W_rope_v(h_f32)
        c_k = self.W_down_k(h_f32)
        c_v = self.W_down_v(h_f32)

        return torch.cat([k_rope, v_rope, c_k, c_v], dim=-1).to(h.dtype)

    def decompress_k(self, compressed: torch.Tensor) -> torch.Tensor:
        """Decompress to full K."""
        k_rope = compressed[..., :self.d_rope].float()
        c_k = compressed[..., 2*self.d_rope:2*self.d_rope+self.d_latent].float()

        k_content = c_k @ self.W_uk.T
        return torch.cat([k_rope, k_content], dim=-1).to(compressed.dtype)

    def decompress_v(self, compressed: torch.Tensor) -> torch.Tensor:
        """Decompress to full V."""
        v_rope = compressed[..., self.d_rope:2*self.d_rope].float()
        c_v = compressed[..., 2*self.d_rope+self.d_latent:].float()

        v_content = c_v @ self.W_uv.T
        return torch.cat([v_rope, v_content], dim=-1).to(compressed.dtype)

    @property
    def cache_dim(self) -> int:
        """Dimension of compressed cache per token."""
        return 2 * self.d_rope + 2 * self.d_latent

    @property
    def compression_ratio(self) -> float:
        """Effective compression ratio."""
        original = 2 * self.d_kv
        compressed = self.cache_dim
        return original / compressed


def init_decoupled_rope_from_weights(
    compression: DecoupledRoPECompression,
    W_k: torch.Tensor,
    W_v: torch.Tensor,
    hidden_states: Optional[torch.Tensor] = None,
) -> Dict[str, float]:
    """Initialize decoupled RoPE compression from original weights.

    Strategy:
    1. First d_rope dimensions of W_k go to W_rope_k (preserves RoPE)
    2. Remaining dimensions compressed via calibration-aware SVD
    """
    d_rope = compression.d_rope
    d_latent = compression.d_latent
    device = W_k.device
    dtype = W_k.dtype

    # Split weights into RoPE and content parts
    # Assuming first d_rope dimensions handle RoPE
    W_k_rope = W_k[:d_rope, :]  # (d_rope, d_model)
    W_v_rope = W_v[:d_rope, :]
    W_k_content = W_k[d_rope:, :]  # (d_content, d_model)
    W_v_content = W_v[d_rope:, :]

    # Set RoPE projections directly
    compression.W_rope_k.weight.data = W_k_rope.clone()
    compression.W_rope_v.weight.data = W_v_rope.clone()

    # Initialize content compression
    if hidden_states is not None:
        # Calibration-aware SVD for content
        H = hidden_states.to(device).float()

        K_content = H @ W_k_content.float().T
        V_content = H @ W_v_content.float().T

        U_k, S_k, _ = torch.linalg.svd(K_content.T, full_matrices=False)
        U_v, S_v, _ = torch.linalg.svd(V_content.T, full_matrices=False)

        W_uk = U_k[:, :d_latent]
        W_uv = U_v[:, :d_latent]

        energy_k = (S_k[:d_latent]**2).sum() / (S_k**2).sum()
        energy_v = (S_v[:d_latent]**2).sum() / (S_v**2).sum()
    else:
        # Weight-only SVD
        U_k, S_k, _ = torch.linalg.svd(W_k_content.float(), full_matrices=False)
        U_v, S_v, _ = torch.linalg.svd(W_v_content.float(), full_matrices=False)

        W_uk = U_k[:, :d_latent]
        W_uv = U_v[:, :d_latent]

        energy_k = (S_k[:d_latent]**2).sum() / (S_k**2).sum()
        energy_v = (S_v[:d_latent]**2).sum() / (S_v**2).sum()

    # Set content compression weights
    W_down_k = W_uk.T @ W_k_content.float()
    W_down_v = W_uv.T @ W_v_content.float()

    compression.W_down_k.weight.data = W_down_k.to(dtype)
    compression.W_down_v.weight.data = W_down_v.to(dtype)
    compression.W_uk.data = W_uk.to(dtype)
    compression.W_uv.data = W_uv.to(dtype)

    return {
        "k_content_energy": energy_k.item(),
        "v_content_energy": energy_v.item(),
        "rope_dim": d_rope,
        "content_latent_dim": d_latent,
        "effective_compression": compression.compression_ratio,
    }


def compare_compression_methods(
    W_k: torch.Tensor,
    W_v: torch.Tensor,
    hidden_states: torch.Tensor,
    d_latent: int,
) -> Dict[str, Dict[str, float]]:
    """Compare different compression methods.

    Returns reconstruction errors and energy captured for:
    1. Weight-only SVD (baseline)
    2. Calibration-aware SVD
    3. Joint K-V SVD
    """
    from .initialization import balanced_svd_init

    results = {}

    # 1. Weight-only SVD (baseline)
    W_down_k, W_down_v, W_uk, W_uv = balanced_svd_init(
        W_k, W_v, d_latent, calibration_data=None, use_randomized_svd=False
    )

    # Compute reconstruction error with calibration data
    H = hidden_states.float().to(W_k.device)
    K = H @ W_k.float().T
    V = H @ W_v.float().T

    K_recon = (H @ W_down_k.float().T) @ W_uk.float().T
    V_recon = (H @ W_down_v.float().T) @ W_uv.float().T

    results["weight_only_svd"] = {
        "k_recon_error": (torch.norm(K - K_recon) / torch.norm(K)).item(),
        "v_recon_error": (torch.norm(V - V_recon) / torch.norm(V)).item(),
    }

    # 2. Calibration-aware SVD
    W_down_k, W_down_v, W_uk, W_uv, stats = calibration_aware_svd(
        W_k, W_v, hidden_states, d_latent
    )
    results["calibration_aware_svd"] = {
        "k_recon_error": stats["k_recon_error"],
        "v_recon_error": stats["v_recon_error"],
        "k_energy": stats["k_energy"],
        "v_energy": stats["v_energy"],
    }

    # 3. Joint K-V SVD
    W_down, W_uk, W_uv, stats = joint_kv_svd(
        W_k, W_v, hidden_states, d_latent
    )
    results["joint_kv_svd"] = {
        "k_recon_error": stats["k_recon_error"],
        "v_recon_error": stats["v_recon_error"],
    }

    return results
